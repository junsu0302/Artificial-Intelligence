{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "64d2e971",
   "metadata": {},
   "source": [
    "# Perceptron"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f30b987f",
   "metadata": {},
   "source": [
    "**Single Layer Perceptron**은 최초로 제안된 신경 모델로 Neural Network에서 가장 간단한 형태다. Single Layer Perceptron은 **Linear classifier(선형 분류)** 을 수행할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aff00b29",
   "metadata": {},
   "source": [
    "Single Layer Perceptron의 **목표**는 Weight 벡터 W와 Bias 파라미터 b로 매개 변수화된 선형 결정 함수를 찾는 것이다.\n",
    "\n",
    "이를 위해서는 다음과 같이 예측 레이블 **$\\hat{y}$** 은 입력 데이터 $x_i$와 실제 레이블 $y_i$가 일치하지 않을 때마다 이러한 매개 변수를 조금씩 조정하여 학습을 진행한다.\n",
    "\n",
    "$\\hat{y} = f(\\sum_{i=1}^{d} WX + b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1136a889",
   "metadata": {},
   "source": [
    "- **$y$** : actual/expected output\n",
    "- **$\\hat{y}$** : predicted output\n",
    "- **$f()$** : non-linear function\n",
    "- **$d$** : number of features \n",
    "- **$W$** : Weight vector\n",
    "- **$X$** : Input data vector\n",
    "- **$b$** : Bias parameter\n",
    "\n",
    "**학습의 목표**는 입출력 관계를 가장 잘 포착하는 $w$와 $b$를 찾는 것이다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f9c316b",
   "metadata": {},
   "source": [
    "Neural Network은 뇌의 뉴런을 바탕으로 만들어졌다. 그래서 다음과 같이 신경망 모델은 생물학적 뉴련과 형태가 비슷하다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eddad027",
   "metadata": {},
   "source": [
    "![1](https://github.com/junsu9637/Artificial-Intelligence/blob/main/Cheat%20Sheet/Artificial%20Intelligence%20Cheat%20Sheet/Image/Perceptron_01.png?raw=true)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b4e8c6a",
   "metadata": {},
   "source": [
    "![2](Image/Perceptron_02.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d76383b",
   "metadata": {},
   "source": [
    "위 그림을 보면 각 뉴런의 **Input(x)** 과 Input의 **Weight(w)** 의 곱을 수행하고 **Bias(b)** 를 더한 후 이를 **Activation function(f(x))** 에 적용하는 것을 볼 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "eb63b34d",
   "metadata": {},
   "source": [
    "클래스 예측은 다음 그림과 같이 특정 샘플의 활성화가 사전 정의된 임계값보다 큰 f(z) 출력을 발생하는지에 따라 달라진다. 이러한 함수를 **non-linear function**이라고 한다. $b$의 경우 $w_0$로 대체하기도 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b17af81e",
   "metadata": {},
   "source": [
    "![3](Image/Perceptron_03.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db0473f7",
   "metadata": {},
   "source": [
    "Perceptron을 코드로 구현하면 다음과 같다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "45947999",
   "metadata": {},
   "source": [
    "위 코드를 부분적을 살펴보자."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf777bbe",
   "metadata": {},
   "source": [
    "## 전역 변수 설정"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "a6ba1292",
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 2\n",
    "NUM_ITER = 2000\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aaea2dad",
   "metadata": {},
   "source": [
    "**Learning rate**는 0.01이 표준값이다. 이는 모델이 얼마나 빨리 배워야 하는지를 나타낸다. Learning rate로 인해 Perceptron이 매우 빠르게 바뀔 수 있기 때문에 Machine Learning에서 사용하는 Hyper parameter 중에서 가장 중요하다고 할 수 있다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a14edb5b",
   "metadata": {},
   "source": [
    "## 논리적 AND 연산 수행"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d8c3953f",
   "metadata": {},
   "source": [
    "이를 구현하기 위해 **sigmoid function**을 활성화 함수로 사용하고 **cross-entropy loss**를 위한 **gradient descent**를 사용한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74a3ebaf",
   "metadata": {},
   "source": [
    "**sigmoid function**의 수식은 다음과 같다.\n",
    "\n",
    "$h(x) = \\frac{1}{1+e^{-x}}$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8a32b45",
   "metadata": {},
   "source": [
    "이 함수 값은 \\[0, 1\\] 영역의 값이고, 전체 함수 값의 총 합이 1이기 때문에 확률 분포로 해석할 수 있다. 이러한 특성을 활용하여  softmax cross-entropy loss를 sigmoid activation으로 공식화할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "4559e99a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Before Learning Weight :[0. 0.]\n",
      "Before Learning Bias :[0.]\n",
      "After Learning Weight :[2.69495   2.6909127]\n",
      "After Learning Bias:[-4.268221]\n",
      "plot_y: [1.7864611 0.3843605]\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYQAAAD4CAYAAADsKpHdAAAAOXRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjUuMCwgaHR0cHM6Ly9tYXRwbG90bGliLm9yZy8/fFQqAAAACXBIWXMAAAsTAAALEwEAmpwYAAAlLElEQVR4nO3dd3hUZf7+8fcnld40AgIKrkoSOoQmIqDLAoqCXxuoiKJGVBRRXBBE0bWAq6IiiqiwKq5gYRGWujZQqqGFNBAriEjvhLTn90dm95fNBpKQYc4kuV/XlcucmWfmuYk5uefMKWPOOUREREK8DiAiIsFBhSAiIoAKQUREfFQIIiICqBBERMQnzOsAJ3PmmWe6hg0beh1DAujo0aP8/PPPHD16FIAaNWpwzjnnEB4e7nEykdJhzZo1u51zUafy2KAuhIYNG5KQkOB1DAmw7OxsXn31VR599FH2799PdnY2zz77LIMHDyY0NNTreCJBzcx+PtXH6i0jCTqhoaEMHTqUlJQUrrrqKg4dOsSQIUPo1KkTiYmJXscTKbNUCBK0GjRowOzZs5k1axZnn302q1atonXr1owYMeI/bymJiP+oECSomRlXX301qampDBkyhJycHJ577jmaNGnCwoULvY4nUqb4pRDMbKqZ7TSzpBPcf5OZJfq+lptZC3/MK+VHtWrVmDhxIitWrKB58+b89NNP9OrVi/79+/P77797HU+kTPDXFsLfgJ4nuf9HoItzrjnwF2CKn+aVcqZ9+/YkJCTw3HPPUbFiRWbMmEF0dDRvvvkmOTk5XscTKdX8UgjOuaXA3pPcv9w5t8+3uBKo7495pXwKDw/n4YcfJjk5mZ49e7J//37i4+Pp0qULKSkpXscTKbW82IdwO7DgRHeaWbyZJZhZwq5duwIYS0qbRo0aMX/+fGbMmEHt2rX55ptvaNmyJWPGjCE9Pd3reCKlTkALwcy6kVsII040xjk3xTkX55yLi4o6pXMrpBwxM2644QZSU1OJj48nMzOTp556iubNm/PFF194HU+kVAlYIZhZc+AtoI9zbk+g5pXyoWbNmrzxxht8/fXXxMbG8t1333HZZZcxcOBAdu/e7XU8kVIhIIVgZucAs4ABzrnNgZhTyqeLL76YdevW8dRTTxEZGcm7775LdHQ077zzDvowKJGT89dhpx8AK4DGZrbNzG43s8FmNtg35DHgDOA1M1tvZroehZw2ERERjB49mo0bN3LppZeyZ88ebr31Vi677DI2b9brEZETsWB+1RQXF+d0LSMpCecc7733Hg8++CB79uwhMjKS0aNHM2LECCIiIryOJ+J3ZrbGORd3Ko/VmcpSppkZt9xyC2lpadx6660cP36cxx57jJYtW/LNN994HU8kqKgQpFw488wzmTZtGl988QUXXHABqampdO7cmTvvvJN9+/YV/gQi5YAKQcqVbt26kZiYyJgxYwgPD+ett94iOjqaDz74QDudpdxTIUi5U6FCBZ588kk2bNhA586d2blzJzfeeCO9evXixx9/9DqeiGdUCFJuxcTE8NVXX/Hmm29So0YNFi1aRJMmTRg/fjyZmZlexxMJOBWClGshISHccccdpKWlceONN3Ls2DFGjhxJXFwcq1at8jqeSECpEESA2rVr8/7777Nw4UIaNWpEYmIiHTt2ZMiQIRw4cMDreCIBoUIQyaNHjx4kJSUxYsQIQkJCmDRpErGxsXzyySfa6SxlngpBJJ9KlSoxbtw41q5dS/v27dm+fTvXXnstffr04ZdffvE6nshpo0IQOYHmzZuzbNkyJk2aRLVq1Zg7dy6xsbG89NJLZGVleR1PxO9UCCInERoayj333ENqairXXHMNR44cYdiwYbRv3561a9d6HU/Er1QIIkVw9tln8/HHHzNnzhwaNGjA2rVradu2LQ8++CCHDx/2Op6IX6gQRIrhyiuvJCUlhWHDhgEwYcIEYmNjmTt3rsfJREpOhSBSTFWqVOHFF19k9erVtG7dmq1bt3LVVVdx7bXXsn37dq/jiZwyFYLIKWrTpg2rVq1iwoQJVK5cmU8++YSYmBhee+01srOzvY4nUmwqBJESCAsL44EHHiAlJYUrr7ySgwcPcu+999KpUycSExO9jidSLCoEET8455xz+PTTT/nkk084++yzWbVqFW3atGHkyJEcPXrU63giRaJCEPETM+P//u//SElJ4d577yU7O5vx48fTtGlTFi1a5HU8kULpIzT9yDlH4pIUPnt/KQd3H6J2wyh63X4ZjZqe43U08cDKlSuJj49n48aNAPTv358JEyZQu3Ztj5NJQVxmCu7ox5CzA0LOxCr2hfBWmJnX0YqlJB+hqULwkx0/7eSRnk+xe/s+jh9JxzkICQ0hLCKMpp0a89jHw6lcrZLXMSXAMjMzmTBhAmPHjuXYsWPUqFGDv/71rwwaNIiQEG2gBwOXcwC37y7ITAEygBzAwCpAaAOs5ltYaB2PUxadPlPZY/t3HeC+DqPYvmUH6YdzywAgJzuHjGMZbPw6jRHdnyQ7S0eelDfh4eH8+c9/JikpiR49erB//37uvPNOunbtSmpqqtfxyj3nMnB7b4TMjUA6uWUA4MAdg6zvcXtuwOUc8jBl4PilEMxsqpntNLOkE9xvZvaKmW0xs0Qza+2PeYPFxy/O5cj+I+TkFLy1lXk8k59Tf2XF3NKxtSP+d95557FgwQL+/ve/c9ZZZ/H111/TokULHnvsMdLT072OV36lz4PsX4ETfSBSNuTsxR39eyBTecZfWwh/A3qe5P5ewAW+r3jgdT/N67ns7Gz+OflfZGac/GJn6YfT+egFnc1anpkZ/fv3JzU1lTvvvJPMzEz+8pe/0KJFC7788kuv45VL7sjb4Ao7Cuw4HH0nIHm85pdCcM4tBfaeZEgf4F2XayVQw8zq+mNurx3Zf5SM9KJ93OLWTb+e5jRSGtSqVYspU6awdOlSYmJi2Lx5M5deeim33noru3fv9jpe+ZJVxMuZ5+zFuYzTmyUIBGofQj1ga57lbb7b/oeZxZtZgpkl7Nq1KyDhSiI0LIScnJzCB5J75UyRf+vcuTPr1q3jySefJDIyknfeeYfo6GjeffddfRhPoFhR10kHlP31N1CFUNBxWwX+xjvnpjjn4pxzcVFRUac5VslVrl6ZOg3PKnRcSGgIbbo3D0AiKU0iIyMZM2YMiYmJdOvWjT179jBw4EC6d+/Od99953W8si+iHQX/econrAlW5PIovQJVCNuABnmW6wNl5ipg/Ub0JbJS5EnHhEeEce2DVwYokZQ2F154IZ9//jl/+9vfOOOMM/j8889p1qwZTz31FBkZZf+tCq9Y5TuACoWMqohVuTMQcTwXqEKYA9ziO9qoA3DAOfdbgOY+7boP7EKzztFEVooo8P7ISpFcM6w357dqFOBkUpqYGQMHDiQtLY2BAwdy/PhxxowZQ6tWrfjmm2+8jlcmWURbqHgNUPEEIypC5CUQebJjZsoOv5yYZmYfAF2BM4HfgceBcADn3GTLPdXvVXKPRDoK3OacK/QYzNJ0YlpWZhbvPD6TT19diIVY7mHMOCpUrsDAJ67niju7ex1RSpkvvviCwYMH/+eto/j4eMaNG0fNmjU9Tla2OOdwR9+Fw6+Re2Ia5L6NZFD5VqzyPaXq7SKdqRxEMtIzSFyaypEDRzmjbg1iL2qsM1LllKWnp/P0008zfvx4MjMzqV27Ni+99BI33HBDqbukQrBzLhsy10D2bgipDhFtMSt4qz+YqRBEyriUlBTi4+NZtmwZAD179uS1116jUSO9DSn/TZeuECnjYmNjWbp0KVOmTKFGjRosXLiQJk2a8Nxzz5GZWbTzYEQKo0IQKSVCQkK48847SU1NpV+/fhw7dowRI0YQFxfH6tWrvY4nZYAKQaSUqVOnDh988AELFiygUaNGJCYm0qFDB+677z4OHjzodTwpxVQIIqVUz549SUpK4s9//jMhISG8+uqrxMTEMGvWLJ3pLKdEhSBSilWqVInx48ezZs0a2rVrx/bt27nmmmvo27cvW7duLfwJRPJQIYiUAS1atGD58uW8+uqrVK1alTlz5hAbG8vLL79MdrY+h0OKRoUgUkaEhoZy7733kpqayjXXXMPhw4d54IEHaN++PWvXrvU6npQCKgSRMqZevXp8/PHHzJkzhwYNGrBmzRratm3LQw89xOHDh72OJ0FMhSBSRl155ZUkJyfzwAMPAPDiiy/SpEkT5s2b520wCVoqBJEyrGrVqkyYMIHVq1fTqlUrfvnlF3r37s11113H9u1l5oLD4icqBJFyoE2bNqxevZoXX3yRypUr8/HHHxMTE8Prr79e5A94krJPhSBSToSFhTFs2DCSk5Pp3bs3Bw8e5J577qFTp05s3LjR63gSBFQIIuXMueeey5w5c/joo4+oW7cuK1eupHXr1jzyyCMcPVrYB85LWaZCECmHzIxrr72W1NRU7rnnHrKzsxk3bhzNmjVj8eLFXscTj6gQRMqx6tWrM2nSJJYtW0azZs344Ycf6NGjBzfddBM7d+70Op4EmApBROjYsSNr1qxh3LhxVKhQgb///e9ER0fz9ttv67pI5YgKQUQACA8PZ8SIESQnJ/OnP/2Jffv2cccdd9C1a1fS0tK8jicBoEIQkf9y3nnnsXDhQt5//33OOussli5dSvPmzXn88cdJT0/3Op6cRioEEfkfZsaNN95Iamoqd9xxB5mZmTz55JO0aNGCr776yut4cpqoEETkhGrVqsWbb77JkiVLiI6OZvPmzXTr1o1BgwaxZ88er+OJn/mlEMysp5ltMrMtZjaygPurm9lcM9tgZslmdps/5hWRwLjkkktYv349TzzxBBEREUybNo3o6Gjee+897XQuQ0pcCGYWCkwCegGxQH8zi8037F4gxTnXAugKvGBmESWdW0QCJzIykscee4zExES6du3K7t27ueWWW+jevTtbtmzxOp74gT+2ENoBW5xzPzjnMoAZQJ98YxxQ1cwMqALsBbL8MLeIBFjjxo354osvmDZtGrVq1eLzzz+nadOmPP3002RkZHgdT0rAH4VQD8j7WX3bfLfl9SoQA2wHNgJDnXMFXlHLzOLNLMHMEnbt2uWHeCLib2bGrbfeSlpaGgMGDOD48eM8+uijtG7dmmXLlnkdT06RPwrBCrgt/5uKPYD1wNlAS+BVM6tW0JM556Y45+Kcc3FRUVF+iCcip0tUVBTvvvsun332Geeffz7JyclcfPHF3HXXXezfv9/reFJM/iiEbUCDPMv1yd0SyOs2YJbLtQX4EYj2w9wiEgQuu+wyEhMTGT16NOHh4UyZMoXo6Ghmzpypnc6liD8K4VvgAjNr5NtR3A+Yk2/ML8BlAGZWG2gM/OCHuUUkSFSsWJGnnnqKdevW0alTJ37//Xf69evHFVdcwU8//eR1PCmCEheCcy4LGAIsAlKBD51zyWY22MwG+4b9BbjIzDYCnwMjnHO7Szq3iASfJk2asHTpUt544w2qV6/OggULaNKkCc8//zxZWTqWJJhZMG/OxcXFuYSEBK9jiMgp2rFjB8OGDWPGjBkAtGjRgilTptCuXTuPk5VdZrbGORd3Ko/VmcoictrUqVOHDz74gPnz59OwYUM2bNhAhw4duP/++zl48KDX8SQfFYKInHa9evUiKSmJhx9+mJCQECZOnEhsbCyzZ8/2OprkoUIQkYCoXLkyzz33HAkJCbRt25Zff/2Vq6++mr59+7J169bCn0BOOxWCiARUy5YtWbFiBRMnTqRq1ap8+umnxMbG8sorr5Cdne11vHJNhSAiARcaGsqQIUNISUnh6quv5vDhwwwdOpQOHTqwbt06r+OVWyoEEfFM/fr1mTVrFrNnz6Z+/fr/eTtp+PDhHDlyxOt45Y4KQUQ816dPH1JSUhg6dCjOOV544QViY2OZN2+e19HKFRWCiASFqlWr8tJLL7Fq1SpatWrFL7/8Qu/evbn++uv57bffvI5XLqgQRCSoxMXFsXr1al544QUqVarERx99RExMDJMnTyYnp8CLJIufqBBEJOiEhYXx4IMPkpKSwhVXXMGBAwe4++676dy5M0lJSV7HK7NUCCIStM4991zmzp3Lhx9+SJ06dVi+fDmtWrVi1KhRHDt2zOt4ZY4KQUSCmplx3XXXkZaWxt133012djbPPvsszZo147PPPvM6XpmiQhCRUqF69eq89tprLFu2jKZNm/L999/TvXt3BgwYwM6dO72OVyaoEESkVOnYsSNr167lmWeeoUKFCkyfPp2YmBimTp2qD+MpIRWCiJQ64eHhPPLIIyQlJdG9e3f27t3L7bffTrdu3di0aZPX8UotFYKIlFp/+MMfWLRoEdOnTycqKoolS5bQvHlzxo4dy/Hjx72OV+qoEESkVDMzbrrpJtLS0hg0aBAZGRk88cQTtGjRgiVLlngdr1RRIYhImVCrVi3efvttvvrqKxo3bsymTZvo2rUrgwYNYs+ePV7HKxVUCCJSpnTp0oUNGzYwduxYIiIimDZtGjExMUyfPl07nQuhQhCRMicyMpLHH3+cxMREunTpwq5duxgwYAA9evTg+++/9zpe0FIhiEiZ1bhxY7788kumTp1KrVq1+Ne//kXTpk159tlnycjI8Dpe0PFLIZhZTzPbZGZbzGzkCcZ0NbP1ZpZsZtrTIyIBYWbcdtttpKWlcfPNN5Oens6oUaNo06YNy5cv9zpeUClxIZhZKDAJ6AXEAv3NLDbfmBrAa8BVzrkmwHUlnVdEpDiioqJ47733WLx4MX/4wx9ISkqiU6dO3H333ezfv9/reEHBH1sI7YAtzrkfnHMZwAygT74xNwKznHO/ADjndJ65iHiie/fubNy4kVGjRhEWFsbkyZOJiYnhww8/LPc7nf1RCPWArXmWt/luy+tCoKaZfWVma8zslhM9mZnFm1mCmSXs2rXLD/FERP5bxYoVefrpp1m3bh0XXXQRO3bs4IYbbqB379789NNPXsfzjD8KwQq4LX/NhgFtgCuAHsAYM7uwoCdzzk1xzsU55+KioqL8EE9EpGBNmzbl66+/ZvLkyVSvXp358+fTpEkTXnjhBbKysryOF3D+KIRtQIM8y/WB7QWMWeicO+Kc2w0sBVr4YW4RkRIJCQnhrrvuIjU1leuvv56jR48yfPhw2rZty7fffut1vIDyRyF8C1xgZo3MLALoB8zJN+ZToLOZhZlZJaA9kOqHuUVE/KJu3brMnDmTefPmce6557J+/Xo6dOjA0KFDOXTokNfxAqLEheCcywKGAIvI/SP/oXMu2cwGm9lg35hUYCGQCKwG3nLO6XPwRCToXH755SQnJzN8+HDMjFdeeYWYmBhmz57tdbTTzoJ5r3pcXJxLSEjwOoaIlFPr168nPj7+P28d9e3bl4kTJ1K/fn2Pk52Yma1xzsWdymN1prKIyAm0bNmSFStW8Morr1ClShVmz55NbGwsEydOJDs72+t4fqdCEBE5idDQUO677z5SU1Pp27cvhw4d4v7776djx46sX7/e63h+pUIQESmC+vXr849//IN//OMf1KtXj2+//Za4uDgefvhhjhw54nU8v1AhiIgUQ9++fUlJSeH+++8nJyeH559/niZNmrBgwQKvo5WYCkFEpJiqVavGyy+/zKpVq2jZsiU///wzl19+Of369WPHjh1exztlKgQRkVP075PX/vrXv1KpUiVmzpxJdHQ0b7zxBjk5OV7HKzYVgohICYSFhTF8+HCSk5Pp1asXBw4cYPDgwXTu3Jnk5GSv4xWLCkFExA8aNmzIvHnzmDlzJnXq1GH58uW0bNmS0aNHc+zYMa/jFYkKQUTET8yM66+/ntTUVO666y6ysrJ45plnaN68OZ999pnX8QqlQhAR8bMaNWowefJkli1bRpMmTdiyZQvdu3dnwIABBPNl/VUIIiKnyUUXXcTatWt5+umnqVChAtOnTyc6Oppp06YF5YfxqBBERE6jiIgIRo0axcaNG/njH//I3r17GTRoEN26dWPTpk1ex/svKgQRkQA4//zzWbx4Me+99x5nnnkmS5YsoXnz5jzxxBMcP37c63iACkFEJGDMjJtvvpm0tDRuu+02MjIyGDt2LC1btmTp0qVex1MhiIgE2hlnnMHUqVP58ssvufDCC0lLS6NLly7ccccd7N2717NcKgQREY907dqVxMREHn/8cSIiInj77beJjo7m/fff92SnswpBRMRDkZGRjB07lg0bNnDJJZewa9cubr75Znr27Mn3338f0CwqBBGRIBAdHc2XX37J22+/Tc2aNVm8eDFNmzZl3LhxZGZmBiSDCkFEJEiEhIQwaNAg0tLSuOmmm0hPT+eRRx6hdevWrFix4vTPf9pnEBGRYjnrrLOYPn06ixcv5rzzziMpKYlOnTpxzz33sH///tM2rwpBRCRIde/enaSkJB555BFCQ0N5/fXXiYmJ4aOPPjotO539Ughm1tPMNpnZFjMbeZJxbc0s28yu9ce8IiJlXcWKFXnmmWdYu3YtHTt2ZMeOHVx//fVceeWV/Pzzz36dq8SFYGahwCSgFxAL9Dez2BOMGw8sKumcIiLlTbNmzfjmm294/fXXqVatGvPmzSM2NpYXX3yRrKwsv8zhjy2EdsAW59wPzrkMYAbQp4Bx9wGfADv9MKeISLkTEhLC4MGDSUtL47rrruPo0aM89NBDtGvXjoSEhJI/vx8y1gO25lne5rvtP8ysHnA1MLmwJzOzeDNLMLOEYL5MrIiIV+rWrcuHH37IP//5T8455xzWrVtH+/bteeCBB0r0vP4oBCvgtvx7O14CRjjnsgt7MufcFOdcnHMuLioqyg/xRETKpiuuuILk5GQeeughAF5++eUSPZ8/CmEb0CDPcn1ge74xccAMM/sJuBZ4zcz6+mFuEZFyrUqVKjz//PMkJCQQFxdXoucK80Oeb4ELzKwR8CvQD7gx7wDnXKN/f29mfwP+6Zyb7Ye5RUQEaNWqFStXriQs7NT/rJe4EJxzWWY2hNyjh0KBqc65ZDMb7Lu/0P0GIiJScqGhoSV6vD+2EHDOzQfm57utwCJwzt3qjzlFRMS/dKayiIgAKgQREfFRIYiICKBCEBERHxWCiIgAKgQREfFRIYiICKBCEBERHxWCiIgAKgQREfFRIYiICKBCEBERHxWCiIgAKgQREfFRIYiICKBCEBERHxWCiIgAKgQREfFRIYiICKBCEBERHxWCiIgAfioEM+tpZpvMbIuZjSzg/pvMLNH3tdzMWvhjXhER8Z8SF4KZhQKTgF5ALNDfzGLzDfsR6OKcaw78BZhS0nlFRMS//LGF0A7Y4pz7wTmXAcwA+uQd4Jxb7pzb51tcCdT3w7wiIuJH/iiEesDWPMvbfLedyO3AghPdaWbxZpZgZgm7du3yQzwRESkKfxSCFXCbK3CgWTdyC2HEiZ7MOTfFORfnnIuLioryQzwRESmKMD88xzagQZ7l+sD2/IPMrDnwFtDLObfHD/OKiIgf+WML4VvgAjNrZGYRQD9gTt4BZnYOMAsY4Jzb7Ic5RUTEz0q8heCcyzKzIcAiIBSY6pxLNrPBvvsnA48BZwCvmRlAlnMurqRzi4iI/5hzBb7dHxTi4uJcQkKC1zFEREoNM1tzqi+4daayiIgAKgQREfFRIYiICKBCEBERHxWCiIgAKgQREfFRIYiICKBCEBERHxWCiIgAKgQREfFRIYiICKBCEBERHxWCiIgAKgQREfFRIYiICKBCEBERHxWCiIgAKgQREfEp8Wcqy/+XnZ1NwqIN/Ou9JRzcfYjaDaPoHd+dxm3P9zqaiJyEc47k5ZtY8Nbn7Nq2hxpnVafnbd1oeWlTQkLKz+tmFYKfbNu8nRF/+guH9h3m2KF0ACzE+GrGMs5rcS5PzX2EqjWreJxSRPLbt/MAo3o9zbbN2zl+NIN/f878yrkJ1KxTg/GLx1Cn4VkepwyM8lN9p9HeHfsY2ulRdm3d858yAHA5jvQjx9mc8APDu40lKzPLw5Qikt/xY8cZ1nkMPyb9QvqR4/8pA4Bjh9PZ8cPvDO00moN7D3mYMnD8Ughm1tPMNpnZFjMbWcD9Zmav+O5PNLPW/pg3WHz4/ByOHjr2X79MeWVlZPHbD7+zbPa3AU4mIifz5QfL2LN9L9mZ2QXen5PjOLzvCHNfXxTgZN4ocSGYWSgwCegFxAL9zSw237BewAW+r3jg9ZLOGyyys7NZ8ObnZGWc/NX/scPpfPzCnAClEpGi+OiFOaQfOX7SMRnpmfzj5fkBSuQtf2whtAO2OOd+cM5lADOAPvnG9AHedblWAjXMrK4f5vbc4X1HyCykDP7t1y07TnMaESmO33/aVaRxh/YeJuN45mlO4z1/FEI9YGue5W2+24o7BgAzizezBDNL2LWraP+zvBQeGU5Odk6RxoaFax++SDAJDQst0jgHhIaV/V2u/vgXWgG35X8zvShjcm90bopzLs45FxcVFVXicKdbpaoVqXdB4Rs7oWEhtLu8VQASiUhRtfpjM8wK+vP036LbnU9oaNHKozTzRyFsAxrkWa4PbD+FMaVWv5F9qVA58qRjwsLDuOaBKwKUSESK4vrhVxFRMeKkYypUjuSGP/cNTCCP+aMQvgUuMLNGZhYB9APy7z2dA9ziO9qoA3DAOfebH+YOCpfd1Jk23VsQWangUoisFMFNj15Do2bnBjiZiJxMbMfG9B3SkwonWHcrVIrk4v9rz0V92gY4mTdK/Ka2cy7LzIYAi4BQYKpzLtnMBvvunwzMBy4HtgBHgdtKOm8wCQkJYcxHDzJz/Kd89MIccrJzMDOys3OocWZVbnv6Ri7tf7HXMUWkAHeMu5n6jc/mncdmcuTAUUJCQ3A5jvDIMPqNvJprhvUu0ttKZYGd6Nj5YBAXF+cSEhK8jlEs2VnZpK7czJEDR6lVtybnt2pUbn6ZREoz5xybE75n3+8HqHZGFRqX0v0GZrbGORd3Ko/VYS9+FhoWStOLY7yOISLFZGbl/rpjZf84KhERKRIVgoiIACoEERHxUSGIiAigQhARER8VgoiIACoEERHxUSGIiAigQhARER8VgoiIACoEERHxUSGIiAigQhARER8VgoiIACoEERHxUSGIiAigQhARER8VgoiIACoEERHxUSGIiAhQwkIws1pm9i8z+87335oFjGlgZl+aWaqZJZvZ0JLMKSIip0dJtxBGAp875y4APvct55cFPOSciwE6APeaWWwJ5xURET8raSH0Ad7xff8O0Df/AOfcb865tb7vDwGpQL0SzisiIn4WVsLH13bO/Qa5f/jN7KyTDTazhkArYNVJxsQD8b7F42aWVMKMXjkT2O11iBJQfm8pv7dKc/7Gp/rAQgvBzD4D6hRw1+jiTGRmVYBPgAeccwdPNM45NwWY4ntMgnMurjjzBIvSnB2U32vK763SnN/MEk71sYUWgnPujyeZ+Hczq+vbOqgL7DzBuHByy+B959ysUw0rIiKnT0n3IcwBBvq+Hwh8mn+AmRnwNpDqnHuxhPOJiMhpUtJCGAd0N7PvgO6+ZczsbDOb7xvTCRgAXGpm631flxfx+aeUMJ+XSnN2UH6vKb+3SnP+U85uzjl/BhERkVJKZyqLiAigQhAREZ+gKYTSehkMM+tpZpvMbIuZ/c+Z2pbrFd/9iWbW2oucJ1KE/Df5ciea2XIza+FFzhMpLH+ecW3NLNvMrg1kvsIUJb+ZdfXte0s2syWBzngiRfjdqW5mc81sgy/7bV7kPBEzm2pmO090rlMpWHcLy1/8ddc5FxRfwHPASN/3I4HxBYypC7T2fV8V2AzEepg5FPgeOA+IADbkzwNcDiwAjNxLd6zy+mddzPwXATV93/cqbfnzjPsCmA9c63XuYv78awApwDm+5bO8zl2M7KP+vR4DUcBeIMLr7HnyXQK0BpJOcH/QrrtFzF/sdTdothAonZfBaAdscc794JzLAGaQ++/Iqw/wrsu1EqjhO2cjGBSa3zm33Dm3z7e4Eqgf4IwnU5SfP8B95J4HU+B5Mh4qSv4bgVnOuV8AnHPB8m8oSnYHVPUdel6F3ELICmzME3POLSU304kE87pbaP5TWXeDqRD+6zIYQIkvgxEA9YCteZa38b8FVZQxXiluttvJfcUULArNb2b1gKuByQHMVVRF+flfCNQ0s6/MbI2Z3RKwdCdXlOyvAjHAdmAjMNQ5lxOYeH4RzOtucRVp3S3ptYyKJdCXwQgAK+C2/MfxFmWMV4qczcy6kftLdfFpTVQ8Rcn/EjDCOZed+0I1qBQlfxjQBrgMqAisMLOVzrnNpztcIYqSvQewHrgU+APwLzP72uN1tjiCed0tsuKsuwEtBFf2LoOxDWiQZ7k+ua+GijvGK0XKZmbNgbeAXs65PQHKVhRFyR8HzPCVwZnA5WaW5ZybHZCEJ1fU35/dzrkjwBEzWwq0IHf/mZeKkv02YJzLfRN7i5n9CEQDqwMTscSCed0tkuKuu8H0llFpvAzGt8AFZtbIzCKAfuT+O/KaA9ziO2KhA3Dg32+NBYFC85vZOcAsYEAQvCrNr9D8zrlGzrmGzrmGwMfAPUFSBlC0359Pgc5mFmZmlYD25O4781pRsv9C7pYNZlab3Ktw/hDQlCUTzOtuoU5p3fV6T3mePeJnkPshO9/5/lvLd/vZwHzf9xeTu8mWSO6m6Hrgco9zX07uq7XvgdG+2wYDg33fGzDJd/9GIM7rn3Ux878F7Mvz807wOnNx8ucb+zeC6CijouYHHib3SKMkct8m9Tx3EX93zgYW+37vk4Cbvc6cL/8HwG9AJrlbA7eXsnW3sPzFXnd16QoREQGC6y0jERHxkApBREQAFYKIiPioEEREBFAhiIiIjwpBREQAFYKIiPj8P48elfs0zp12AAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.array([[0, 0], [1, 0], [1, 1], [0, 1]], np.float32) # 4x2, input\n",
    "y = np.array([0, 0, 1, 0], np.float32) # 4, correct output\n",
    " \n",
    "W = np.zeros(NUM_FEATURES, np.float32) # 2x1, weight\n",
    "b = np.zeros(1, np.float32) # 1x1\n",
    "\n",
    "print('Before Learning Weight :' + str(W))\n",
    "print('Before Learning Bias :' + str(b))\n",
    " \n",
    "N, d = np.shape(x) # number of samples and number of features\n",
    " \n",
    "# 각 샘플을 개별적을 처리\n",
    "for k in range(NUM_ITER):\n",
    "    for j in range(N):\n",
    "        yHat_j = x[j, :].dot(W) + b # 1x2, 2x1\n",
    "        yHat_j = 1.0 / (1.0 + np.exp(-yHat_j)) # sigmoid\n",
    " \n",
    "        err = y[j] - yHat_j\n",
    "        deltaW = err * x[j, :]\n",
    "        deltaB = err\n",
    "        W = W + learning_rate * deltaW\n",
    "        b = b + learning_rate * deltaB\n",
    "        \n",
    "# 벡터화를 통한 개선 코드\n",
    "'''\n",
    "for k in range(NUM_ITER):\n",
    "    yHat = x.dot(W) + b\n",
    "    yHat = 1.0 / (1.0 + np.exp(-yHat))\n",
    "    err = y - yHat\n",
    "    deltaW = np.transpose(x).dot(err)           # have to 2x1\n",
    "    deltaB = np.sum(err)                        # have to 1x1. collect error from all the 4 samples\n",
    "    W = W + learning_rate * deltaW\n",
    "    b = b + learning_rate * deltaB\n",
    "'''\n",
    "\n",
    "# 적합선 계산\n",
    "plot_x = np.array([np.min(x[:, 0] - 0.2), np.max(x[:, 1]+0.2)])\n",
    "plot_y = - 1 / W[1] * (W[0] * plot_x + b) # comes from, w0*x + w1*y + b = 0 then y = (-1/w1) (w0*x + b)\n",
    " \n",
    "    \n",
    "# 출력\n",
    "print('After Learning Weight :' + str(W))\n",
    "print('After Learning Bias:' + str(b))\n",
    "print('plot_y: '+ str(plot_y))\n",
    " \n",
    "plt.scatter(x[:, 0], x[:, 1], c=y, s=100, cmap='viridis')\n",
    "plt.plot(plot_x, plot_y, color='k', linewidth=2)\n",
    "plt.xlim([-0.2, 1.2]); plt.ylim([-0.2, 1.25]);\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfb69623",
   "metadata": {},
   "source": [
    "- x :  4x2 입력 데이터(4는 sample의 수, 2는 feature의 수)\n",
    "- W : Weight로 데이터 dimensionality(차원성)의 크기\n",
    "- d : feature의 수(=데이터의 dimensionality)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "55733cd7",
   "metadata": {},
   "source": [
    "각 샘플은 각 반복에서 별도로 처리한다. Model은 Prediction을 수정하기 위해 매번 `y-yHat` 오차를 계산한다.\n",
    "\n",
    "W, b를 갱신하는 과정을 반복하면서 yHat이 점점 y에 가까워진다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12ad49f7",
   "metadata": {},
   "source": [
    "flot_y의 공식은 다음과 같다. \n",
    "\n",
    "$w_1 x + w_2 y + b$를 변형하여 다음과 같이 표현한다.\n",
    "\n",
    "$y = -\\frac{1}{w_2}(w_1 x + b)$"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "96ff87fa",
   "metadata": {},
   "source": [
    "이런 식을 통해 산출한 예측에 의한 오류를 delta라고 표기한다. 퍼셉트론은 Learnong rate를 이용하여 Weight와 Bias를 조절하여 다음 예측이 조금 더 나아지게 만든다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8f4ee66b",
   "metadata": {},
   "source": [
    "위 코드는 매 반복마다 각 샘플을 하나씩 처리한다. 다음과 같이 공식을 벡터화하고, 루프를 위한 여분을 제거하면 프로그램을 더 빠르게 실행할 수 있다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "982bc3b8",
   "metadata": {},
   "outputs": [],
   "source": [
    "for k in range(NUM_ITER):\n",
    "    yHat = x.dot(W) + b\n",
    "    yHat = 1.0 / (1.0 + np.exp(-yHat))\n",
    " \n",
    "    err = y - yHat\n",
    " \n",
    "    deltaW = np.transpose(x).dot(err) # have to 2x1\n",
    "    deltaB = np.sum(err) # have to 1x1. collect error from all the 4 samples\n",
    "    W = W + learning_rate * deltaW # if err = y - yHat, then W = W + lRate * deltW\n",
    "    b = b + learning_rate * deltaB"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c253423",
   "metadata": {},
   "source": [
    "위 코드에서 deltaW와 deltaB는 오차항과 곱하기 전에 입력 x를 전치한다. 이러한 방식은 선형 대수 기법이라고 한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41d47655",
   "metadata": {},
   "source": [
    "크기가 4x2인 x와 크기가 4x1인 err에서 2x1 크기의 weight 배열을 얻을 수 있는 유일한 방법은 x를 전치하고 err와 곱하는 방법이다. 따라서 **deltaW**에서 x를 전치 후 err과 곱하여 2x1 배열을 얻는다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "23c5ba01",
   "metadata": {},
   "source": [
    "**deltaB**는 4개의 오차항을 모두 합하여 모든 샘플에서 발생한 오류를 수집한다."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cdd861d6",
   "metadata": {},
   "source": [
    "아래 코드는 위 코드를 수정하여 100번 학습을 진행할 때 마다 Weight, Bias, gradient를 출력하도록 만들었다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "4214adce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Weight :[0.14675088 0.14675088]\n",
      "Bias:[-0.6805278]\n",
      "gradient :[4.8372993 3.4372995]\n",
      "Weight :[0.38720825 0.38720825]\n",
      "Bias:[-1.0805309]\n",
      "gradient :[2.990568  1.5905678]\n",
      "Weight :[0.62093836 0.62093836]\n",
      "Bias:[-1.3953761]\n",
      "gradient :[2.4472055 1.0472054]\n",
      "Weight :[0.8321302 0.8321302]\n",
      "Bias:[-1.6704844]\n",
      "gradient :[2.2074797 0.8074796]\n",
      "Weight :[1.0215605 1.0215605]\n",
      "Bias:[-1.9193554]\n",
      "gradient :[2.0788465 0.6788463]\n",
      "Weight :[1.1926794 1.1926794]\n",
      "Bias:[-2.147776]\n",
      "gradient :[2.000799 0.600799]\n",
      "Weight :[1.348727 1.348727]\n",
      "Bias:[-2.359253]\n",
      "gradient :[1.9492441  0.54924417]\n",
      "Weight :[1.4923031 1.4923031]\n",
      "Bias:[-2.5563436]\n",
      "gradient :[1.9130191 0.5130189]\n",
      "Weight :[1.6254281 1.6254281]\n",
      "Bias:[-2.7410414]\n",
      "gradient :[1.8863506  0.48635048]\n",
      "Weight :[1.7496762 1.7496762]\n",
      "Bias:[-2.9149487]\n",
      "gradient :[1.8659933 0.4659932]\n",
      "Weight :[1.8662899 1.8662899]\n",
      "Bias:[-3.0793707]\n",
      "gradient :[1.849996  0.4499959]\n",
      "Weight :[1.9762589 1.9762589]\n",
      "Bias:[-3.2353826]\n",
      "gradient :[1.837125   0.43712485]\n",
      "Weight :[2.0803878 2.0803878]\n",
      "Bias:[-3.3838818]\n",
      "gradient :[1.826563   0.42656294]\n",
      "Weight :[2.179336 2.179336]\n",
      "Bias:[-3.5256197]\n",
      "gradient :[1.8177495 0.4177494]\n",
      "Weight :[2.2736466 2.2736466]\n",
      "Bias:[-3.6612363]\n",
      "gradient :[1.8102926 0.4102926]\n",
      "Weight :[2.3637815 2.3637815]\n",
      "Bias:[-3.7912796]\n",
      "gradient :[1.8039043  0.40390438]\n",
      "Weight :[2.4501295 2.4501295]\n",
      "Bias:[-3.9162204]\n",
      "gradient :[1.7983729 0.3983728]\n",
      "Weight :[2.5330257 2.5330257]\n",
      "Bias:[-4.036474]\n",
      "gradient :[1.7935386  0.39353848]\n",
      "Weight :[2.6127584 2.6127584]\n",
      "Bias:[-4.152398]\n",
      "gradient :[1.7892773  0.38927743]\n",
      "Weight :[2.6895783 2.6895783]\n",
      "Bias:[-4.26431]\n",
      "gradient :[1.7854939  0.38549384]\n"
     ]
    }
   ],
   "source": [
    "x = np.array([[0, 0], [1, 0], [1, 1], [0, 1]], np.float32)\n",
    "y = np.array([0, 0, 1, 0], np.float32)\n",
    " \n",
    "W = np.zeros(NUM_FEATURES, np.float32)\n",
    "b = np.zeros(1, np.float32)\n",
    " \n",
    "N, d = np.shape(x)\n",
    "\n",
    "cnt = 0\n",
    "\n",
    "for k in range(NUM_ITER):\n",
    "    yHat = x.dot(W) + b\n",
    "    yHat = 1.0 / (1.0 + np.exp(-yHat))\n",
    "    err = y - yHat\n",
    "    deltaW = np.transpose(x).dot(err)\n",
    "    deltaB = np.sum(err)    \n",
    "    W = W + learning_rate * deltaW\n",
    "    b = b + learning_rate * deltaB\n",
    "    cnt = cnt + 1\n",
    "    \n",
    "    if(cnt % 100 == 0):\n",
    "        plot_x = np.array([np.min(x[:, 0] - 0.2), np.max(x[:, 1]+0.2)])\n",
    "        plot_y = - 1 / W[1] * (W[0] * plot_x + b)\n",
    "        print('Weight :' + str(W))\n",
    "        print('Bias:' + str(b))\n",
    "        print('gradient :' + str(plot_y))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
